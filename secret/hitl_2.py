import os
import uuid
from typing import TypedDict

from getpass import getpass
from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search import TavilySearchTool
from langchain.agents import create_agent
from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import Command, interrupt

# --- (Optional) Set API Keys ---
# os.environ["OPENAI_API_KEY"] = getpass("Enter your OpenAI API key: ")
# os.environ["TAVILY_API_KEY"] = getpass("Enter your Tavily API key: ")

# --- Define the Graph State (used by sub-graphs) ---
class SubGraphState(TypedDict):
    """
    The state for our sub-graphs (Planner and Executor).
    Attributes:
        agent_output: The last text generated by the agent.
        user_feedback: The last input from the user (can be the initial query or modifications).
    """
    agent_output: str
    user_feedback: str


# ==============================================================================
# --- 1. DEFINE GRAPH 1 (PLANNER) ---
# (This is the same as before, it's our first "module")
# ==============================================================================

print("Defining Graph 1 (Planner)...")

# --- 1a. Create Planner Agent ---
PLANNER_PROMPT = """You are a master planner. You will be given a user query.
Your goal is to break down the query into a clear, step-by-step plan.
You do not need to execute the plan, only create it.
If the user provides feedback, refine your plan based on their modifications."""
planner_model = ChatOpenAI(model="gpt-4o", temperature=0)
planner_checkpointer = MemorySaver()
planner_agent_runnable = create_agent(
    model=planner_model,
    system_prompt=PLANNER_PROMPT,
    tools=[],
    checkpointer=planner_checkpointer,
)

# --- 1b. Define Planner Graph Nodes ---
def planner_agent_node(state: SubGraphState):
    """Runs the planner agent."""
    print("--- ü§ñ PLANNER NODE RUNNING ---")
    user_input = state["user_feedback"]
    # We must pass the config to the runnable
    config = {"configurable": {"thread_id": state["thread_id"]}}
    response = planner_agent_runnable.invoke(
        {"messages": [HumanMessage(content=user_input)]}, config
    )
    new_output = response['messages'][-1].content
    print(f"--- Planner Generated: '{new_output}' ---")
    return {"agent_output": new_output}

def planner_review_node(state: SubGraphState):
    """Pauses for human to review the *plan*."""
    print("--- ‚è∏Ô∏è PAUSING FOR PLAN REVIEW ---")
    output_to_review = state["agent_output"]
    feedback = interrupt({
        "instruction": "Please review the *PLAN*. Type 'approve' to execute, or provide feedback to modify the plan.",
        "content_to_review": output_to_review
    })
    print(f"---  resumed with plan feedback: '{feedback}' ---")
    return {"user_feedback": feedback}

# --- 1c. Define Planner Conditional Edge ---
def decide_to_finish_planner(state: SubGraphState):
    """Checks user feedback. If 'approve', routes to END."""
    print("--- üßê PLAN DECISION NODE ---")
    if state["user_feedback"].lower() == "approve":
        print("--- Decision: Plan Approved. Ending planner graph. ---")
        return END
    else:
        print("--- Decision: Plan modifications received. Looping back to planner. ---")
        return "agent"

# --- 1d. Assemble Planner Graph ---
planner_builder = StateGraph(SubGraphState)
planner_builder.add_node("agent", planner_agent_node)
planner_builder.add_node("review", planner_review_node)
planner_builder.set_entry_point("agent")
planner_builder.add_edge("agent", "review")
planner_builder.add_conditional_edges(
    "review",
    decide_to_finish_planner,
    {"agent": "agent", END: END}
)
# We add `thread_id` to the state so the agent node can access it
planner_graph = planner_builder.compile(
    checkpointer=planner_checkpointer, 
    interrupt_before_nodes=["review"]
).with_types(input_type=SubGraphState, output_type=SubGraphState)
print("Graph 1 (Planner) compiled.")


# ==============================================================================
# --- 2. DEFINE GRAPH 2 (EXECUTOR) ---
# (This is the same as before, it's our second "module")
# ==============================================================================

print("\nDefining Graph 2 (Executor)...")

# --- 2a. Create Executor Agent ---
EXECUTOR_PROMPT = """You are a helpful assistant. You will be given a user query (which may be a plan) and must generate a response.
You have access to tools. You must use them if the query requires outside information.
You will also be given feedback on your previous generations. You must use this feedback
and your memory of the conversation to generate a new, improved response that
incorporates the user's modifications."""
executor_tools = [TavilySearchTool(max_results=2)]
executor_model = ChatOpenAI(model="gpt-4o", temperature=0)
executor_checkpointer = MemorySaver()
executor_agent_runnable = create_agent(
    model=executor_model,
    system_prompt=EXECUTOR_PROMPT,
    tools=executor_tools,
    checkpointer=executor_checkpointer,
)

# --- 2b. Define Executor Graph Nodes ---
def executor_agent_node(state: SubGraphState):
    """Runs the executor agent."""
    print("--- ü§ñ EXECUTOR NODE RUNNING ---")
    user_input = state["user_feedback"]
    config = {"configurable": {"thread_id": state["thread_id"]}}
    response = executor_agent_runnable.invoke(
        {"messages": [HumanMessage(content=user_input)]}, config
    )
    new_output = response['messages'][-1].content
    print(f"--- Executor Generated: '{new_output}' ---")
    return {"agent_output": new_output}

def executor_review_node(state: SubGraphState):
    """Pauses for human to review the *final result*."""
    print("--- ‚è∏Ô∏è PAUSING FOR RESULT REVIEW ---")
    output_to_review = state["agent_output"]
    feedback = interrupt({
        "instruction": "Please review the *RESULT*. Type 'approve' to finish, or provide feedback for modifications.",
        "content_to_review": output_to_review
    })
    print(f"---  resumed with result feedback: '{feedback}' ---")
    return {"user_feedback": feedback}

# --- 2c. Define Executor Conditional Edge ---
def decide_to_finish_executor(state: SubGraphState):
    """Checks user feedback. If 'approve', routes to END."""
    print("--- üßê RESULT DECISION NODE ---")
    if state["user_feedback"].lower() == "approve":
        print("--- Decision: Result Approved. Ending executor graph. ---")
        return END
    else:
        print("--- Decision: Result modifications received. Looping back to executor. ---")
        return "agent"

# --- 2d. Assemble Executor Graph ---
executor_builder = StateGraph(SubGraphState)
executor_builder.add_node("agent", executor_agent_node)
executor_builder.add_node("review", executor_review_node)
executor_builder.set_entry_point("agent")
executor_builder.add_edge("agent", "review")
executor_builder.add_conditional_edges(
    "review",
    decide_to_finish_executor,
    {"agent": "agent", END: END}
)
executor_graph = executor_builder.compile(
    checkpointer=executor_checkpointer,
    interrupt_before_nodes=["review"]
).with_types(input_type=SubGraphState, output_type=SubGraphState)
print("Graph 2 (Executor) compiled.")


# ==============================================================================
# --- 3. DEFINE THE SUPER-GRAPH ---
# ==============================================================================

print("\nDefining Super-Graph...")

class SuperGraphState(TypedDict):
    """
    The state for the high-level graph.
    Attributes:
        initial_query: The user's starting query.
        approved_plan: The final, approved plan from the planner graph.
        final_result: The final, approved result from the executor graph.
    """
    initial_query: str
    approved_plan: str
    final_result: str

# --- 3a. Define Super-Graph Nodes ---

def run_planner_node(state: SuperGraphState):
    """
    This node *runs* the entire planner graph.
    It will handle its own internal review loop.
    """
    print("\n--- üèÅ ENTERING PLANNER GRAPH ---")
    
    # Create a unique ID for this sub-graph
    planner_thread_id = f"planner-{uuid.uuid4()}"
    planner_config = {"configurable": {"thread_id": planner_thread_id}}
    
    # Start the planner graph
    initial_query = state["initial_query"]
    planner_initial_state = {"user_feedback": initial_query, "thread_id": planner_thread_id}
    planner_current_state = planner_graph.invoke(planner_initial_state, planner_config)

    # Start the loop to handle *planner* interruptions
    while "__interrupt__" in planner_current_state:
        interrupt_data = planner_current_state["__interrupt__"]
        
        print("\n--- ‚ùó PLAN REVIEW (from Super-Graph) ---")
        print(f"Instruction: {interrupt_data['instruction']}")
        print("---------------------------------")
        print(f"Agent's Plan:\n{interrupt_data['content_to_review']}")
        print("---------------------------------")
        
        user_feedback = input("Your feedback on the *plan* ('approve' to continue): ")
        print("\n====================================")
        
        planner_current_state = planner_graph.invoke(
            Command(resume=user_feedback),
            planner_config,
        )

    print("\n--- ‚úÖ Plan Approved ---")
    # The final approved plan is in the 'agent_output' of the last state
    approved_plan = planner_current_state["agent_output"]
    print(f"Final Approved Plan:\n{approved_plan}")
    
    return {"approved_plan": approved_plan}


def run_executor_node(state: SuperGraphState):
    """
    This node *runs* the entire executor graph.
    It uses the `approved_plan` from the state as its input.
    """
    print("\n--- üèÅ ENTERING EXECUTOR GRAPH ---")
    
    # Create a unique ID for this sub-graph
    executor_thread_id = f"executor-{uuid.uuid4()}"
    executor_config = {"configurable": {"thread_id": executor_thread_id}}
    
    # The *initial query* for this graph is the *approved plan*
    approved_plan = state["approved_plan"]
    executor_initial_state = {"user_feedback": approved_plan, "thread_id": executor_thread_id}
    executor_current_state = executor_graph.invoke(executor_initial_state, executor_config)

    # Start the loop to handle *executor* interruptions
    while "__interrupt__" in executor_current_state:
        interrupt_data = executor_current_state["__interrupt__"]
        
        print("\n--- ‚ùó RESULT REVIEW (from Super-Graph) ---")
        print(f"Instruction: {interrupt_data['instruction']}")
        print("---------------------------------")
        print(f"Agent's Result:\n{interrupt_data['content_to_review']}")
        print("---------------------------------")
        
        user_feedback = input("Your feedback on the *result* ('approve' to end): ")
        print("\n====================================")
        
        executor_current_state = executor_graph.invoke(
            Command(resume=user_feedback),
            executor_config,
        )

    print("\n--- ‚úÖ Result Approved ---")
    final_result = executor_current_state["agent_output"]
    print(f"Final Approved Result:\n{final_result}")
    
    return {"final_result": final_result}


# --- 3b. Assemble Super-Graph ---
super_builder = StateGraph(SuperGraphState)

super_builder.add_node("planner", run_planner_node)
super_builder.add_node("executor", run_executor_node)

super_builder.set_entry_point("planner")
super_builder.add_edge("planner", "executor")
super_builder.add_edge("executor", END)

# No checkpointer needed for this simple super-graph,
# as the sub-graphs manage their own state.
super_graph = super_builder.compile()
print("Super-Graph compiled.")


# ==============================================================================
# --- 4. Run the Full Super-Graph ---
# ==============================================================================

print("\n--- üöÄ RUNNING SUPER-GRAPH ---")

# Get the initial query from the user
initial_query = input("Please enter your initial high-level query: ")
print("\n====================================")

# Invoke the super-graph *once*.
# It will handle all internal loops and human feedback.
final_state = super_graph.invoke({"initial_query": initial_query})

print("\n--- ‚úÖ Entire Process Finished ---")
print(f"Final Approved Result:\n{final_state['final_result']}")