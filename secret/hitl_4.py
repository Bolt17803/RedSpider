import os
import uuid
from typing import TypedDict

from getpass import getpass
from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search import TavilySearchTool
# --- NEW ---
from langchain.tools import tool
# --- END NEW ---
from langchain.agents import create_agent
from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import Command, interrupt

# --- (Optional) Set API Keys ---
# os.environ["OPENAI_API_KEY"] = getpass("Enter your OpenAI API key: ")
# os.environ["TAVILY_API_KEY"] = getpass("Enter your Tavily API key: ")

# --- Define the Graph State (used by sub-graphs) ---
class SubGraphState(TypedDict):
    """
    The state for our sub-graphs (Planner and Executor).
    Attributes:
        agent_output: The last text generated by the agent.
        user_feedback: The last input from the user (can be the initial query or modifications).
        thread_id: The unique ID for the sub-graph's thread.
    """
    agent_output: str
    user_feedback: str
    thread_id: str # --- MODIFIED: Added thread_id here for clarity ---


# ==============================================================================
# --- 1. DEFINE GRAPH 1 (PLANNER) ---
# (This is the same as before, it's our first "module")
# ==============================================================================

print("Defining Graph 1 (Planner)...")

# --- 1a. Create Planner Agent ---
PLANNER_PROMPT = """You are a master planner. You will be given a user query.
Your goal is to break down the query into a clear, step-by-step plan.
You do not need to execute the plan, only create it.
If the user provides feedback, refine your plan based on their modifications."""
planner_model = ChatOpenAI(model="gpt-4o", temperature=0)
planner_checkpointer = MemorySaver()
planner_agent_runnable = create_agent(
    model=planner_model,
    system_prompt=PLANNER_PROMPT,
    tools=[],
    checkpointer=planner_checkpointer,
)

# --- 1b. Define Planner Graph Nodes ---
def planner_agent_node(state: SubGraphState):
    """Runs the planner agent."""
    print("--- ü§ñ PLANNER NODE RUNNING ---")
    user_input = state["user_feedback"]
    # We must pass the config to the runnable
    config = {"configurable": {"thread_id": state["thread_id"]}}
    response = planner_agent_runnable.invoke(
        {"messages": [HumanMessage(content=user_input)]}, config
    )
    new_output = response['messages'][-1].content
    print(f"--- Planner Generated: '{new_output}' ---")
    return {"agent_output": new_output}

def planner_review_node(state: SubGraphState):
    """Pauses for human to review the *plan*."""
    print("--- ‚è∏Ô∏è PAUSING FOR PLAN REVIEW ---")
    output_to_review = state["agent_output"]
    feedback = interrupt({
        "instruction": "Please review the *PLAN*. Type 'approve' to execute, or provide feedback to modify the plan.",
        "content_to_review": output_to_review
    })
    print(f"---  resumed with plan feedback: '{feedback}' ---")
    return {"user_feedback": feedback}

# --- 1c. Define Planner Conditional Edge ---
def decide_to_finish_planner(state: SubGraphState):
    """Checks user feedback. If 'approve', routes to END."""
    print("--- üßê PLAN DECISION NODE ---")
    if state["user_feedback"].lower() == "approve":
        print("--- Decision: Plan Approved. Ending planner graph. ---")
        return END
    else:
        print("--- Decision: Plan modifications received. Looping back to planner. ---")
        return "agent"

# --- 1d. Assemble Planner Graph ---
planner_builder = StateGraph(SubGraphState)
planner_builder.add_node("agent", planner_agent_node)
planner_builder.add_node("review", planner_review_node)
planner_builder.set_entry_point("agent")
planner_builder.add_edge("agent", "review")
planner_builder.add_conditional_edges(
    "review",
    decide_to_finish_planner,
    {"agent": "agent", END: END}
)
# Compile the graph with its checkpointer
planner_graph = planner_builder.compile(
    checkpointer=planner_checkpointer, 
    interrupt_before_nodes=["review"]
).with_types(input_type=SubGraphState, output_type=SubGraphState)
print("Graph 1 (Planner) compiled.")


# ==============================================================================
# --- 2. DEFINE GRAPH 2 (EXECUTOR) ---
# (This section has all the new changes)
# ==============================================================================

print("\nDefining Graph 2 (Executor)...")

# --- NEW: Define the Workspace and Safety Functions ---
WORKSPACE_PATH = os.path.abspath("./agent_workspace")
os.makedirs(WORKSPACE_PATH, exist_ok=True)
print(f"Agent workspace initialized at: {WORKSPACE_PATH}")

def _get_safe_path(file_path: str) -> str:
    """
    Joins the workspace path with the file path and ensures
    the resulting path is still within the workspace.
    Prevents path traversal attacks.
    """
    # Join the base workspace path with the user-provided path
    full_path = os.path.abspath(os.path.join(WORKSPACE_PATH, file_path))
    
    # Check if the resulting path is still within the workspace
    if not full_path.startswith(WORKSPACE_PATH):
        raise ValueError("Error: Path is outside the designated workspace.")
    
    return full_path

# --- NEW: Define File System Tools ---

@tool
def write_file(file_path: str, content: str) -> str:
    """
    Writes text content to a file in the agent's workspace.
    The file_path should be relative (e.g., 'my_script.py' or 'project/main.py').
    """
    try:
        safe_path = _get_safe_path(file_path)
        # Ensure parent directory exists
        os.makedirs(os.path.dirname(safe_path), exist_ok=True)
        with open(safe_path, 'w', encoding='utf-8') as f:
            f.write(content)
        return f"Successfully wrote to file: {file_path}"
    except Exception as e:
        return f"Error writing file: {e}"

@tool
def read_file(file_path: str) -> str:
    """
    Reads text content from a file in the agent's workspace.
    The file_path should be relative (e.g., 'my_script.py').
    """
    try:
        safe_path = _get_safe_path(file_path)
        with open(safe_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        return f"Error reading file: {e}"

@tool
def create_directory(directory_path: str) -> str:
    """
    Creates a new directory (and any parent directories) in the agent's workspace.
    The directory_path should be relative (e.g., 'my_project/src').
    """
    try:
        safe_path = _get_safe_path(directory_path)
        os.makedirs(safe_path, exist_ok=True)
        return f"Successfully created directory: {directory_path}"
    except Exception as e:
        return f"Error creating directory: {e}"

@tool
def list_directory(directory_path: str = ".") -> str:
    """
    Lists the contents of a directory in the agent's workspace.
    The directory_path should be relative (e.g., '.' or 'my_project').
    """
    try:
        safe_path = _get_safe_path(directory_path)
        entries = os.listdir(safe_path)
        if not entries:
            return f"Directory '{directory_path}' is empty."
        return f"Contents of '{directory_path}':\n" + "\n".join(entries)
    except Exception as e:
        return f"Error listing directory: {e}"

# --- NEW: Update the Executor Prompt ---
EXECUTOR_PROMPT = """You are a helpful assistant and a coding expert. 
You will be given a user query (which may be a plan) and must generate a response.

You have access to tools, including a file system.
All file operations (read, write, create_directory, list_directory) are 
restricted to a sandboxed workspace. 
You MUST use these tools to write or read code or any files.
Always use relative paths like 'my_script.py' or 'my_project/main.py'.
Do not just output code in markdown blocks unless you are also writing it to a file.

You must also use your search tool if the query requires outside information.

You will also be given feedback on your previous generations. You must use this feedback
and your memory of the conversation to generate a new, improved response that
incorporates the user's modifications."""

# --- NEW: Add new tools to the tool list ---
executor_tools = [
    TavilySearchTool(max_results=2),
    write_file,
    read_file,
    create_directory,
    list_directory
]
# --- END NEW ---

executor_model = ChatOpenAI(model="gpt-4o", temperature=0)
executor_checkpointer = MemorySaver()
executor_agent_runnable = create_agent(
    model=executor_model,
    system_prompt=EXECUTOR_PROMPT,
    tools=executor_tools, # --- MODIFIED: Pass the expanded tool list ---
    checkpointer=executor_checkpointer,
)

# --- 2b. Define Executor Graph Nodes ---
def executor_agent_node(state: SubGraphState):
    """Runs the executor agent."""
    print("--- ü§ñ EXECUTOR NODE RUNNING ---")
    user_input = state["user_feedback"]
    config = {"configurable": {"thread_id": state["thread_id"]}}
    response = executor_agent_runnable.invoke(
        {"messages": [HumanMessage(content=user_input)]}, config
    )
    new_output = response['messages'][-1].content
    print(f"--- Executor Generated: '{new_output}' ---")
    return {"agent_output": new_output}

def executor_review_node(state: SubGraphState):
    """Pauses for human to review the *final result*."""
    print("--- ‚è∏Ô∏è PAUSING FOR RESULT REVIEW ---")
    output_to_review = state["agent_output"]
    feedback = interrupt({
        "instruction": "Please review the *RESULT*. Type 'approve' to finish, or provide feedback for modifications.",
        "content_to_review": output_to_review
    })
    print(f"---  resumed with result feedback: '{feedback}' ---")
    return {"user_feedback": feedback}

# --- 2c. Define Executor Conditional Edge ---
def decide_to_finish_executor(state: SubGraphState):
    """Checks user feedback. If 'approve', routes to END."""
    print("--- üßê RESULT DECISION NODE ---")
    if state["user_feedback"].lower() == "approve":
        print("--- Decision: Result Approved. Ending executor graph. ---")
        return END
    else:
        print("--- Decision: Result modifications received. Looping back to executor. ---")
        return "agent"

# --- 2d. Assemble Executor Graph ---
executor_builder = StateGraph(SubGraphState)
executor_builder.add_node("agent", executor_agent_node)
executor_builder.add_node("review", executor_review_node)
executor_builder.set_entry_point("agent")
executor_builder.add_edge("agent", "review")
executor_builder.add_conditional_edges(
    "review",
    decide_to_finish_executor,
    {"agent": "agent", END: END}
)
executor_graph = executor_builder.compile(
    checkpointer=executor_checkpointer,
    interrupt_before_nodes=["review"]
).with_types(input_type=SubGraphState, output_type=SubGraphState)
print("Graph 2 (Executor) compiled.")


# ==============================================================================
# --- 3. DEFINE THE SUPER-GRAPH ---
# (This section is unchanged, but I've added `thread_id` to the state
#  to make the sub-graph calls cleaner)
# ==============================================================================

print("\nDefining Super-Graph...")

class SuperGraphState(TypedDict):
    """
    The state for the high-level graph.
    Attributes:
        initial_query: The user's starting query.
        approved_plan: The final, approved plan from the planner graph.
        final_result: The final, approved result from the executor graph.
    """
    initial_query: str
    approved_plan: str
    final_result: str

# --- 3a. Define Super-Graph Nodes ---

def run_planner_node(state: SuperGraphState):
    """
    This node *runs* the entire planner graph.
    It will handle its own internal review loop.
    """
    print("\n--- üèÅ ENTERING PLANNER GRAPH ---")
    
    # Create a unique ID for this sub-graph
    planner_thread_id = f"planner-{uuid.uuid4()}"
    planner_config = {"configurable": {"thread_id": planner_thread_id}}
    
    # Start the planner graph
    initial_query = state["initial_query"]
    planner_initial_state = {"user_feedback": initial_query, "thread_id": planner_thread_id}
    planner_current_state = planner_graph.invoke(planner_initial_state, planner_config)

    # Start the loop to handle *planner* interruptions
    while "__interrupt__" in planner_current_state:
        interrupt_data = planner_current_state["__interrupt__"]
        
        print("\n--- ‚ùó PLAN REVIEW (from Super-Graph) ---")
        print(f"Instruction: {interrupt_data['instruction']}")
        print("---------------------------------")
        print(f"Agent's Plan:\n{interrupt_data['content_to_review']}")
        print("---------------------------------")
        
        user_feedback = input("Your feedback on the *plan* ('approve' to continue): ")
        print("\n====================================")
        
        planner_current_state = planner_graph.invoke(
            Command(resume=user_feedback),
            planner_config,
        )

    print("\n--- ‚úÖ Plan Approved ---")
    # The final approved plan is in the 'agent_output' of the last state
    approved_plan = planner_current_state["agent_output"]
    print(f"Final Approved Plan:\n{approved_plan}")
    
    return {"approved_plan": approved_plan}


def run_executor_node(state: SuperGraphState):
    """
    This node *runs* the entire executor graph.
    It uses the `approved_plan` from the state as its input.
    """
    print("\n--- üèÅ ENTERING EXECUTOR GRAPH ---")
    
    # Create a unique ID for this sub-graph
    executor_thread_id = f"executor-{uuid.uuid4()}"
    executor_config = {"configurable": {"thread_id": executor_thread_id}}
    
    # The *initial query* for this graph is the *approved plan*
    approved_plan = state["approved_plan"]
    executor_initial_state = {"user_feedback": approved_plan, "thread_id": executor_thread_id}
    executor_current_state = executor_graph.invoke(executor_initial_state, executor_config)

    # Start the loop to handle *executor* interruptions
    while "__interrupt__" in executor_current_state:
        interrupt_data = executor_current_state["__interrupt__"]
        
        print("\n--- ‚ùó RESULT REVIEW (from Super-Graph) ---")
        print(f"Instruction: {interrupt_data['instruction']}")
        print("---------------------------------")
        print(f"Agent's Result:\n{interrupt_data['content_to_review']}")
        print("---------------------------------")
        
        user_feedback = input("Your feedback on the *result* ('approve' to end): ")
        print("\n====================================")
        
        executor_current_state = executor_graph.invoke(
            Command(resume=user_feedback),
            executor_config,
        )

    print("\n--- ‚úÖ Result Approved ---")
    final_result = executor_current_state["agent_output"]
    print(f"Final Approved Result:\n{final_result}")
    
    return {"final_result": final_result}


# --- 3b. Assemble Super-Graph ---
super_builder = StateGraph(SuperGraphState)

super_builder.add_node("planner", run_planner_node)
super_builder.add_node("executor", run_executor_node)

super_builder.set_entry_point("planner")
super_builder.add_edge("planner", "executor")
super_builder.add_edge("executor", END)

# No checkpointer needed for this simple super-graph,
# as the sub-graphs manage their own state.
super_graph = super_builder.compile()
print("Super-Graph compiled.")


# ==============================================================================
# --- 4. Run the Full Super-Graph ---
# (This section is unchanged)
# ==============================================================================

print("\n--- üöÄ RUNNING SUPER-GRAPH ---")

# Get the initial query from the user
initial_query = input("Please enter your initial high-level query: ")
print("\n====================================")

# Invoke the super-graph *once*.
# It will handle all internal loops and human feedback.
final_state = super_graph.invoke({"initial_query": initial_query})

print("\n--- ‚úÖ Entire Process Finished ---")
print(f"Final Approved Result:\n{final_state['final_result']}")

