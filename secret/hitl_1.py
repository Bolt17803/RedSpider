import os
import uuid
from typing import TypedDict

from getpass import getpass
from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search import TavilySearchTool
from langchain.agents import create_agent
from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import Command, interrupt

# --- (Optional) Set API Keys ---
# os.environ["OPENAI_API_KEY"] = getpass("Enter your OpenAI API key: ")
# os.environ["TAVILY_API_KEY"] = getpass("Enter your Tavily API key: ")

# --- Define the Graph State (used by both graphs) ---
class AgentState(TypedDict):
    """
    The state for our graphs.
    Attributes:
        agent_output: The last text generated by the agent.
        user_feedback: The last input from the user (can be the initial query or modifications).
    """
    agent_output: str
    user_feedback: str


# ==============================================================================
# --- 1. DEFINE GRAPH 1 (PLANNER) ---
# ==============================================================================

print("Defining Graph 1 (Planner)...")

# --- 1a. Create Planner Agent ---
PLANNER_PROMPT = """You are a master planner. You will be given a user query.
Your goal is to break down the query into a clear, step-by-step plan.
You do not need to execute the plan, only create it.
If the user provides feedback, refine your plan based on their modifications."""

# Create the LLM for the planner
planner_model = ChatOpenAI(model="gpt-4o", temperature=0)

# Create the planner agent's internal memory
planner_checkpointer = MemorySaver()

# Create the planner agent_runnable (no tools needed for this simple planner)
planner_agent_runnable = create_agent(
    model=planner_model,
    system_prompt=PLANNER_PROMPT,
    tools=[],  # No tools for the planner, it just thinks
    checkpointer=planner_checkpointer,
)

# --- 1b. Define Planner Graph Nodes ---

def planner_agent_node(state: AgentState):
    """Runs the planner agent."""
    print("--- ü§ñ PLANNER NODE RUNNING ---")
    user_input = state["user_feedback"]
    response = planner_agent_runnable.invoke(
        {"messages": [HumanMessage(content=user_input)]}
    )
    new_output = response['messages'][-1].content
    print(f"--- Planner Generated: '{new_output}' ---")
    return {"agent_output": new_output}

def planner_review_node(state: AgentState):
    """Pauses for human to review the *plan*."""
    print("--- ‚è∏Ô∏è PAUSING FOR PLAN REVIEW ---")
    output_to_review = state["agent_output"]
    feedback = interrupt({
        "instruction": "Please review the *PLAN*. Type 'approve' to execute, or provide feedback to modify the plan.",
        "content_to_review": output_to_review
    })
    print(f"---  resumed with plan feedback: '{feedback}' ---")
    return {"user_feedback": feedback}

# --- 1c. Define Planner Conditional Edge ---

def decide_to_finish_planner(state: AgentState):
    """Checks user feedback. If 'approve', routes to END."""
    print("--- üßê PLAN DECISION NODE ---")
    if state["user_feedback"].lower() == "approve":
        print("--- Decision: Plan Approved. Ending planner graph. ---")
        return END
    else:
        print("--- Decision: Plan modifications received. Looping back to planner. ---")
        return "agent"

# --- 1d. Assemble Planner Graph ---

planner_builder = StateGraph(AgentState)
planner_builder.add_node("agent", planner_agent_node)
planner_builder.add_node("review", planner_review_node)
planner_builder.set_entry_point("agent")
planner_builder.add_edge("agent", "review")
planner_builder.add_conditional_edges(
    "review",
    decide_to_finish_planner,
    {"agent": "agent", END: END}
)

# Compile the planner graph with its *own* checkpointer
planner_graph = planner_builder.compile(checkpointer=planner_checkpointer)
print("Graph 1 (Planner) compiled.")


# ==============================================================================
# --- 2. DEFINE GRAPH 2 (EXECUTOR) ---
# ==============================================================================

print("\nDefining Graph 2 (Executor)...")

# --- 2a. Create Executor Agent ---
EXECUTOR_PROMPT = """You are a helpful assistant. You will be given a user query (which may be a plan) and must generate a response.
You have access to tools. You must use them if the query requires outside information.
You will also be given feedback on your previous generations. You must use this feedback
and your memory of the conversation to generate a new, improved response that
incorporates the user's modifications."""

# Define tools for the executor agent
executor_tools = [TavilySearchTool(max_results=2)]
executor_model = ChatOpenAI(model="gpt-4o", temperature=0)

# Create the executor agent's *separate* internal memory
executor_checkpointer = MemorySaver()

# Create the executor agent_runnable
executor_agent_runnable = create_agent(
    model=executor_model,
    system_prompt=EXECUTOR_PROMPT,
    tools=executor_tools,
    checkpointer=executor_checkpointer,  # This is the executor's memory
)

# --- 2b. Define Executor Graph Nodes ---

def executor_agent_node(state: AgentState):
    """Runs the executor agent."""
    print("--- ü§ñ EXECUTOR NODE RUNNING ---")
    user_input = state["user_feedback"]
    response = executor_agent_runnable.invoke(
        {"messages": [HumanMessage(content=user_input)]}
    )
    new_output = response['messages'][-1].content
    print(f"--- Executor Generated: '{new_output}' ---")
    return {"agent_output": new_output}

def executor_review_node(state: AgentState):
    """Pauses for human to review the *final result*."""
    print("--- ‚è∏Ô∏è PAUSING FOR RESULT REVIEW ---")
    output_to_review = state["agent_output"]
    feedback = interrupt({
        "instruction": "Please review the *RESULT*. Type 'approve' to finish, or provide feedback for modifications.",
        "content_to_review": output_to_review
    })
    print(f"---  resumed with result feedback: '{feedback}' ---")
    return {"user_feedback": feedback}

# --- 2c. Define Executor Conditional Edge ---

def decide_to_finish_executor(state: AgentState):
    """Checks user feedback. If 'approve', routes to END."""
    print("--- üßê RESULT DECISION NODE ---")
    if state["user_feedback"].lower() == "approve":
        print("--- Decision: Result Approved. Ending executor graph. ---")
        return END
    else:
        print("--- Decision: Result modifications received. Looping back to executor. ---")
        return "agent"

# --- 2d. Assemble Executor Graph ---

executor_builder = StateGraph(AgentState)
executor_builder.add_node("agent", executor_agent_node)
executor_builder.add_node("review", executor_review_node)
executor_builder.set_entry_point("agent")
executor_builder.add_edge("agent", "review")
executor_builder.add_conditional_edges(
    "review",
    decide_to_finish_executor,
    {"agent": "agent", END: END}
)

# Compile the executor graph with its *own* checkpointer
executor_graph = executor_builder.compile(checkpointer=executor_checkpointer)
print("Graph 2 (Executor) compiled.")


# ==============================================================================
# --- 3. Run the Full Graph-of-Graphs Loop ---
# ==============================================================================

# --- 3a. Run Graph 1 (Planner) Loop ---
print("\n--- STARTING PLANNER GRAPH (GRAPH 1) ---")

# Create a unique ID for the planner conversation
planner_thread_id = f"planner-{uuid.uuid4()}"
planner_config = {"configurable": {"thread_id": planner_thread_id}}

# Get the initial query from the user
initial_query = input("Please enter your initial high-level query: ")
print("\n====================================")

# Start the planner graph
planner_initial_state = {"user_feedback": initial_query}
planner_current_state = planner_graph.invoke(planner_initial_state, planner_config)

# Start the loop to handle *planner* interruptions
while "__interrupt__" in planner_current_state:
    interrupt_data = planner_current_state["__interrupt__"]
    
    print("\n--- ‚ùó PLAN REVIEW ---")
    print(f"Instruction: {interrupt_data['instruction']}")
    print("---------------------------------")
    print(f"Agent's Plan:\n{interrupt_data['content_to_review']}")
    print("---------------------------------")
    
    user_feedback = input("Your feedback on the *plan* ('approve' to continue): ")
    print("\n====================================")
    
    planner_current_state = planner_graph.invoke(
        Command(resume=user_feedback),
        planner_config,
    )

print("\n--- ‚úÖ Plan Approved ---")
# The final approved plan is in the 'agent_output' of the last state
approved_plan = planner_current_state["agent_output"]
print(f"Final Approved Plan:\n{approved_plan}")


# --- 3b. Run Graph 2 (Executor) Loop ---
print("\n--- STARTING EXECUTOR GRAPH (GRAPH 2) ---")

# Create a unique ID for the executor conversation
executor_thread_id = f"executor-{uuid.uuid4()}"
executor_config = {"configurable": {"thread_id": executor_thread_id}}

# The *initial query* for this graph is the *approved plan* from Graph 1
executor_initial_state = {"user_feedback": approved_plan}
executor_current_state = executor_graph.invoke(executor_initial_state, executor_config)

# Start the loop to handle *executor* interruptions
while "__interrupt__" in executor_current_state:
    interrupt_data = executor_current_state["__interrupt__"]
    
    print("\n--- ‚ùó RESULT REVIEW ---")
    print(f"Instruction: {interrupt_data['instruction']}")
    print("---------------------------------")
    print(f"Agent's Result:\n{interrupt_data['content_to_review']}")
    print("---------------------------------")
    
    user_feedback = input("Your feedback on the *result* ('approve' to end): ")
    print("\n====================================")
    
    executor_current_state = executor_graph.invoke(
        Command(resume=user_feedback),
        executor_config,
    )

# 4. If the loop breaks, the entire process is finished
print("\n--- ‚úÖ Entire Process Finished ---")
print("Final approved result:")
print(executor_current_state["agent_output"])

